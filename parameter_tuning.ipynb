{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from GA.evolution_utils import evolution\n",
    "from GA.evolution_utils import X_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_n_evolution_pt(n):\n",
    "    co_prob = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    mu_prob = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09]\n",
    "    avg_scores = []\n",
    "    for j in mu_prob:\n",
    "        result_n_runs = []\n",
    "        for i in range(n):\n",
    "            st = time.time()\n",
    "            chromo_set_2, score_set_2 = evolution(\n",
    "                size=100, \n",
    "                features_count=100,\n",
    "                chromo_size=X_bow.shape[1],\n",
    "                n_parents=80,\n",
    "                crossover_pb=0.3,\n",
    "                mutation_pb=j,\n",
    "                mutation_rate=0.05,\n",
    "                n_gen=100\n",
    "            )\n",
    "            et = time.time()\n",
    "            result_n_runs.append((chromo_set_2, score_set_2, et-st))\n",
    "\n",
    "        avg_acc = np.array(result_n_runs[0][1])\n",
    "        for i in result_n_runs[1:]:\n",
    "            avg_acc += i[1]\n",
    "        avg_scores.append([avg_acc/n, j])\n",
    "\n",
    "    return avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score in generation 1 : 0.616 feat_count: (100,)\n",
      "Population size: 100\n",
      "Best score in generation 2 : 0.616 feat_count: (100,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pt_avg_scores \u001b[39m=\u001b[39m run_n_evolution_pt(\u001b[39m5\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m, in \u001b[0;36mrun_n_evolution_pt\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n):\n\u001b[0;32m      8\u001b[0m     st \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m----> 9\u001b[0m     chromo_set_2, score_set_2 \u001b[39m=\u001b[39m evolution(\n\u001b[0;32m     10\u001b[0m         size\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \n\u001b[0;32m     11\u001b[0m         features_count\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[0;32m     12\u001b[0m         chromo_size\u001b[39m=\u001b[39;49mX_bow\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m],\n\u001b[0;32m     13\u001b[0m         n_parents\u001b[39m=\u001b[39;49m\u001b[39m80\u001b[39;49m,\n\u001b[0;32m     14\u001b[0m         crossover_pb\u001b[39m=\u001b[39;49m\u001b[39m0.3\u001b[39;49m,\n\u001b[0;32m     15\u001b[0m         mutation_pb\u001b[39m=\u001b[39;49mj,\n\u001b[0;32m     16\u001b[0m         mutation_rate\u001b[39m=\u001b[39;49m\u001b[39m0.05\u001b[39;49m,\n\u001b[0;32m     17\u001b[0m         n_gen\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m\n\u001b[0;32m     18\u001b[0m     )\n\u001b[0;32m     19\u001b[0m     et \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     20\u001b[0m     result_n_runs\u001b[39m.\u001b[39mappend((chromo_set_2, score_set_2, et\u001b[39m-\u001b[39mst))\n",
      "File \u001b[1;32mc:\\Users\\student\\Documents\\deva\\GA-SC\\GA\\evolution_utils.py:373\u001b[0m, in \u001b[0;36mevolution\u001b[1;34m(size, features_count, chromo_size, n_parents, crossover_pb, mutation_pb, mutation_rate, n_gen)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest score in generation\u001b[39m\u001b[39m'\u001b[39m,i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m,scores[\u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mfeat_count:\u001b[39m\u001b[39m\"\u001b[39m, np\u001b[39m.\u001b[39mwhere(pop_after_fit[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[0;32m    371\u001b[0m pop_after_sel \u001b[39m=\u001b[39m population_selection(pop_after_fit,n_parents)\n\u001b[1;32m--> 373\u001b[0m pop_after_cross \u001b[39m=\u001b[39m single_point_crossover1(pop_after_sel, crossover_pb, n_parents)\n\u001b[0;32m    375\u001b[0m population_nextgen \u001b[39m=\u001b[39m bit_flip_mutation1(pop_after_cross, mutation_pb, mutation_rate, features_count, n_parents)\n\u001b[0;32m    377\u001b[0m \u001b[39m# new next gen population will have the evolved population + the initial population after fitness_score\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[39m# _, population_new_nextgen = fitness_score(population_nextgen)\u001b[39;00m\n\u001b[0;32m    379\u001b[0m \u001b[39m# population_nextgen = population_selection(population_new_nextgen, n_parents)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\student\\Documents\\deva\\GA-SC\\GA\\evolution_utils.py:290\u001b[0m, in \u001b[0;36msingle_point_crossover1\u001b[1;34m(pop_after_sel, probability, n_parents)\u001b[0m\n\u001b[0;32m    287\u001b[0m         pop_nextgen\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39marray(parent_1))\n\u001b[0;32m    288\u001b[0m         pop_nextgen\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39marray(parent_2))\n\u001b[1;32m--> 290\u001b[0m _, pop_nextgen \u001b[39m=\u001b[39m fitness_score(pop_nextgen)\n\u001b[0;32m    291\u001b[0m \u001b[39mreturn\u001b[39;00m pop_nextgen[:n_parents]\n",
      "File \u001b[1;32mc:\\Users\\student\\Documents\\deva\\GA-SC\\GA\\evolution_utils.py:348\u001b[0m, in \u001b[0;36mfitness_score\u001b[1;34m(population)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[39mfor\u001b[39;00m chromosome \u001b[39min\u001b[39;00m population:\n\u001b[0;32m    347\u001b[0m     features \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(chromosome\u001b[39m!=\u001b[39m\u001b[39m0\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> 348\u001b[0m     logmodel\u001b[39m.\u001b[39;49mfit(X_train[:,features],Y_train)         \n\u001b[0;32m    349\u001b[0m     predictions \u001b[39m=\u001b[39m logmodel\u001b[39m.\u001b[39mpredict(X_test[:,features])\n\u001b[0;32m    350\u001b[0m     scores\u001b[39m.\u001b[39mappend(accuracy_score(Y_test,predictions))\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\dev-ml\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:474\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    463\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    465\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    466\u001b[0m ]\n\u001b[0;32m    468\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 474\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    475\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    476\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    477\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    478\u001b[0m )(\n\u001b[0;32m    479\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    480\u001b[0m         t,\n\u001b[0;32m    481\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    482\u001b[0m         X,\n\u001b[0;32m    483\u001b[0m         y,\n\u001b[0;32m    484\u001b[0m         sample_weight,\n\u001b[0;32m    485\u001b[0m         i,\n\u001b[0;32m    486\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    487\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    488\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    489\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    490\u001b[0m     )\n\u001b[0;32m    491\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    492\u001b[0m )\n\u001b[0;32m    494\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\dev-ml\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\dev-ml\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\dev-ml\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\dev-ml\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\dev-ml\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\dev-ml\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\dev-ml\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\dev-ml\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\dev-ml\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 185\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\dev-ml\\lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\dev-ml\\lib\\site-packages\\sklearn\\tree\\_classes.py:224\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    223\u001b[0m \u001b[39mif\u001b[39;00m is_classification:\n\u001b[1;32m--> 224\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    225\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(y)\n\u001b[0;32m    227\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\dev-ml\\lib\\site-packages\\sklearn\\utils\\multiclass.py:199\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_classification_targets\u001b[39m(y):\n\u001b[0;32m    188\u001b[0m     \u001b[39m\"\"\"Ensure that target y is of a non-regression type.\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[39m    Only the following target types (as defined in type_of_target) are allowed:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39m        Target values.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m     y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    200\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[0;32m    201\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    202\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    206\u001b[0m     ]:\n\u001b[0;32m    207\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\dev-ml\\lib\\site-packages\\sklearn\\utils\\multiclass.py:363\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[39m# Check multiclass\u001b[39;00m\n\u001b[0;32m    362\u001b[0m first_row \u001b[39m=\u001b[39m y[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(y) \u001b[39melse\u001b[39;00m y\u001b[39m.\u001b[39mgetrow(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mdata\n\u001b[1;32m--> 363\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39;49munique_values(y)\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m (y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(first_row) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m    364\u001b[0m     \u001b[39m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[0;32m    365\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m suffix\n\u001b[0;32m    366\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\dev-ml\\lib\\site-packages\\sklearn\\utils\\_array_api.py:84\u001b[0m, in \u001b[0;36m_NumPyApiWrapper.unique_values\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munique_values\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m numpy\u001b[39m.\u001b[39;49munique(x)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\dev-ml\\lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[0;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\student\\anaconda3\\envs\\dev-ml\\lib\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    334\u001b[0m     aux \u001b[39m=\u001b[39m ar[perm]\n\u001b[0;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     ar\u001b[39m.\u001b[39;49msort()\n\u001b[0;32m    337\u001b[0m     aux \u001b[39m=\u001b[39m ar\n\u001b[0;32m    338\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(aux\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool_)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pt_avg_scores = run_n_evolution_pt(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('n_run_az_ga_100fc_pt_avg.pkl', 'wb') as wf:\n",
    "    pickle.dump([pt_avg_scores], wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([0.6504, 0.6504, 0.6504, 0.652 , 0.652 , 0.6528, 0.6552, 0.6568,\n",
      "       0.6616, 0.6672, 0.6792, 0.6792, 0.6832, 0.6848, 0.6888, 0.6896,\n",
      "       0.696 , 0.6968, 0.7   , 0.7   , 0.7008, 0.7048, 0.7048, 0.708 ,\n",
      "       0.7104, 0.7112, 0.7112, 0.7128, 0.7128, 0.7144, 0.7176, 0.7176,\n",
      "       0.7192, 0.7192, 0.7232, 0.7264, 0.7272, 0.728 , 0.7288, 0.732 ,\n",
      "       0.732 , 0.7336, 0.7344, 0.7368, 0.7368, 0.7368, 0.7376, 0.7384,\n",
      "       0.7384, 0.74  , 0.7416, 0.7424, 0.7432, 0.7432, 0.7448, 0.7464,\n",
      "       0.7472, 0.7472, 0.748 , 0.7496, 0.7496, 0.7496, 0.7512, 0.756 ,\n",
      "       0.756 , 0.7584, 0.7592, 0.76  , 0.7608, 0.7608, 0.7656, 0.7656,\n",
      "       0.7664, 0.7664, 0.7664, 0.7704, 0.772 , 0.772 , 0.7728, 0.7736,\n",
      "       0.7736, 0.7752, 0.7752, 0.776 , 0.776 , 0.7776, 0.7792, 0.7792,\n",
      "       0.7792, 0.78  , 0.7832, 0.7832, 0.784 , 0.7848, 0.7856, 0.7856,\n",
      "       0.7864, 0.7872, 0.7872, 0.788 ]), 0.1], [array([0.6304, 0.6368, 0.6432, 0.6504, 0.656 , 0.6568, 0.6576, 0.6664,\n",
      "       0.6672, 0.668 , 0.6704, 0.6728, 0.6768, 0.6824, 0.6832, 0.6856,\n",
      "       0.6912, 0.6912, 0.6912, 0.6944, 0.696 , 0.696 , 0.6984, 0.7016,\n",
      "       0.7024, 0.7024, 0.704 , 0.7064, 0.7064, 0.7064, 0.7064, 0.708 ,\n",
      "       0.7104, 0.7112, 0.7112, 0.7128, 0.7152, 0.7152, 0.7152, 0.716 ,\n",
      "       0.7168, 0.7192, 0.7232, 0.724 , 0.7248, 0.7264, 0.7264, 0.7264,\n",
      "       0.7344, 0.7352, 0.736 , 0.7376, 0.7384, 0.7384, 0.74  , 0.74  ,\n",
      "       0.7408, 0.7424, 0.7432, 0.7432, 0.7464, 0.7464, 0.7464, 0.7464,\n",
      "       0.7504, 0.7504, 0.7504, 0.7504, 0.7504, 0.7504, 0.7504, 0.7504,\n",
      "       0.7504, 0.7504, 0.7504, 0.7512, 0.752 , 0.752 , 0.752 , 0.752 ,\n",
      "       0.752 , 0.7528, 0.7528, 0.7536, 0.7536, 0.7536, 0.7536, 0.7536,\n",
      "       0.7536, 0.7536, 0.7544, 0.7544, 0.7544, 0.7544, 0.7544, 0.7552,\n",
      "       0.7568, 0.7568, 0.7576, 0.7576]), 0.2], [array([0.6432, 0.648 , 0.6496, 0.6552, 0.6592, 0.6608, 0.6672, 0.6672,\n",
      "       0.6712, 0.6768, 0.6768, 0.68  , 0.6824, 0.692 , 0.692 , 0.6928,\n",
      "       0.6992, 0.6992, 0.7008, 0.7032, 0.7072, 0.7152, 0.716 , 0.7176,\n",
      "       0.72  , 0.7232, 0.7248, 0.7296, 0.732 , 0.7336, 0.736 , 0.74  ,\n",
      "       0.7408, 0.7432, 0.744 , 0.7448, 0.7448, 0.7472, 0.7496, 0.7496,\n",
      "       0.7496, 0.752 , 0.7536, 0.7552, 0.7552, 0.756 , 0.7608, 0.7624,\n",
      "       0.7624, 0.764 , 0.7648, 0.7664, 0.7688, 0.7696, 0.7704, 0.772 ,\n",
      "       0.7728, 0.7736, 0.7752, 0.7752, 0.7752, 0.7752, 0.7768, 0.7768,\n",
      "       0.7768, 0.7776, 0.7784, 0.7784, 0.7784, 0.7792, 0.7792, 0.7808,\n",
      "       0.7808, 0.7816, 0.7816, 0.784 , 0.784 , 0.7848, 0.7856, 0.7856,\n",
      "       0.7864, 0.7872, 0.788 , 0.7888, 0.7896, 0.792 , 0.792 , 0.7928,\n",
      "       0.7928, 0.7928, 0.7936, 0.7944, 0.7944, 0.7992, 0.8   , 0.8   ,\n",
      "       0.8016, 0.8016, 0.8024, 0.8024]), 0.3], [array([0.6416, 0.6424, 0.644 , 0.6552, 0.6624, 0.6648, 0.672 , 0.6728,\n",
      "       0.6776, 0.6832, 0.6856, 0.696 , 0.7   , 0.7024, 0.7032, 0.704 ,\n",
      "       0.7048, 0.7056, 0.7056, 0.7056, 0.7088, 0.7104, 0.7128, 0.7128,\n",
      "       0.7152, 0.7152, 0.716 , 0.7168, 0.7168, 0.7176, 0.7176, 0.7184,\n",
      "       0.7192, 0.7232, 0.7256, 0.7264, 0.7264, 0.7264, 0.7288, 0.7288,\n",
      "       0.7288, 0.7296, 0.7296, 0.7296, 0.732 , 0.732 , 0.732 , 0.7328,\n",
      "       0.7352, 0.7368, 0.7376, 0.7376, 0.74  , 0.74  , 0.74  , 0.7416,\n",
      "       0.7416, 0.7416, 0.7464, 0.7472, 0.7472, 0.7472, 0.7496, 0.7512,\n",
      "       0.7512, 0.752 , 0.752 , 0.7528, 0.7536, 0.7536, 0.7536, 0.7544,\n",
      "       0.7552, 0.7552, 0.7552, 0.7552, 0.7552, 0.7552, 0.7552, 0.7552,\n",
      "       0.7552, 0.756 , 0.756 , 0.756 , 0.756 , 0.7584, 0.7584, 0.7616,\n",
      "       0.7616, 0.7632, 0.7632, 0.7632, 0.7688, 0.7688, 0.7688, 0.7688,\n",
      "       0.7696, 0.7712, 0.7712, 0.772 ]), 0.4], [array([0.6496, 0.6568, 0.6616, 0.6632, 0.672 , 0.6776, 0.6824, 0.6848,\n",
      "       0.6912, 0.6912, 0.6944, 0.6984, 0.7016, 0.7032, 0.7064, 0.708 ,\n",
      "       0.7096, 0.7112, 0.7136, 0.7184, 0.7216, 0.7216, 0.7264, 0.728 ,\n",
      "       0.7296, 0.732 , 0.7328, 0.7328, 0.7352, 0.7384, 0.7392, 0.7424,\n",
      "       0.7432, 0.744 , 0.7464, 0.7512, 0.752 , 0.7528, 0.7528, 0.7536,\n",
      "       0.7536, 0.7536, 0.7552, 0.7576, 0.7592, 0.76  , 0.7608, 0.7624,\n",
      "       0.7624, 0.7624, 0.7632, 0.764 , 0.7664, 0.7664, 0.7664, 0.7672,\n",
      "       0.768 , 0.7704, 0.7704, 0.7744, 0.7752, 0.776 , 0.7768, 0.7776,\n",
      "       0.7776, 0.7776, 0.7784, 0.7792, 0.7792, 0.7808, 0.7808, 0.7808,\n",
      "       0.7808, 0.7808, 0.7808, 0.7808, 0.7816, 0.7816, 0.7816, 0.7824,\n",
      "       0.7824, 0.7832, 0.784 , 0.7856, 0.7856, 0.7872, 0.788 , 0.7888,\n",
      "       0.7888, 0.7888, 0.792 , 0.792 , 0.7936, 0.7936, 0.7936, 0.7944,\n",
      "       0.7944, 0.7944, 0.7944, 0.7952]), 0.5], [array([0.6256, 0.6336, 0.6456, 0.6576, 0.6624, 0.6664, 0.6712, 0.6816,\n",
      "       0.6824, 0.6832, 0.6856, 0.6872, 0.6888, 0.6904, 0.692 , 0.6944,\n",
      "       0.6968, 0.6984, 0.7   , 0.7024, 0.7032, 0.7048, 0.7072, 0.708 ,\n",
      "       0.7088, 0.7104, 0.7144, 0.7144, 0.7144, 0.7224, 0.7224, 0.7224,\n",
      "       0.7248, 0.7256, 0.7272, 0.7296, 0.7312, 0.7328, 0.7336, 0.7336,\n",
      "       0.7376, 0.7376, 0.7384, 0.74  , 0.7408, 0.7416, 0.7424, 0.7424,\n",
      "       0.7424, 0.7456, 0.7504, 0.7504, 0.752 , 0.7528, 0.7536, 0.7536,\n",
      "       0.756 , 0.756 , 0.7576, 0.7576, 0.7576, 0.7592, 0.7592, 0.76  ,\n",
      "       0.76  , 0.7608, 0.764 , 0.764 , 0.7648, 0.7648, 0.7664, 0.7672,\n",
      "       0.7688, 0.7696, 0.7696, 0.7728, 0.7744, 0.7744, 0.7784, 0.7792,\n",
      "       0.78  , 0.78  , 0.78  , 0.78  , 0.78  , 0.78  , 0.78  , 0.78  ,\n",
      "       0.7808, 0.7816, 0.7816, 0.7816, 0.7824, 0.7832, 0.7832, 0.7832,\n",
      "       0.7832, 0.7848, 0.7848, 0.7856]), 0.6], [array([0.6384, 0.6472, 0.6608, 0.668 , 0.668 , 0.6776, 0.6864, 0.6864,\n",
      "       0.688 , 0.6904, 0.6912, 0.696 , 0.6968, 0.6976, 0.6984, 0.7   ,\n",
      "       0.7032, 0.7064, 0.7112, 0.7128, 0.7168, 0.7192, 0.7216, 0.7248,\n",
      "       0.7264, 0.7264, 0.7312, 0.732 , 0.732 , 0.7328, 0.7328, 0.736 ,\n",
      "       0.7368, 0.7392, 0.7408, 0.7416, 0.7416, 0.7424, 0.7432, 0.7432,\n",
      "       0.7432, 0.7456, 0.7464, 0.7464, 0.7464, 0.7496, 0.752 , 0.7528,\n",
      "       0.7552, 0.7552, 0.7584, 0.76  , 0.76  , 0.7608, 0.7608, 0.7616,\n",
      "       0.7616, 0.764 , 0.764 , 0.764 , 0.7648, 0.7664, 0.7688, 0.7712,\n",
      "       0.7736, 0.7736, 0.7752, 0.7752, 0.7776, 0.7776, 0.7784, 0.7784,\n",
      "       0.7784, 0.7792, 0.7792, 0.7792, 0.7792, 0.7792, 0.78  , 0.78  ,\n",
      "       0.78  , 0.7808, 0.7808, 0.7808, 0.7816, 0.7824, 0.7824, 0.7832,\n",
      "       0.7832, 0.784 , 0.784 , 0.784 , 0.784 , 0.784 , 0.784 , 0.784 ,\n",
      "       0.784 , 0.784 , 0.784 , 0.784 ]), 0.7], [array([0.6328, 0.6416, 0.6544, 0.6656, 0.6752, 0.6784, 0.6808, 0.6816,\n",
      "       0.6832, 0.6848, 0.688 , 0.6888, 0.6912, 0.6928, 0.696 , 0.6984,\n",
      "       0.7   , 0.7024, 0.7032, 0.7048, 0.712 , 0.712 , 0.72  , 0.72  ,\n",
      "       0.72  , 0.724 , 0.7248, 0.7248, 0.7272, 0.7288, 0.7336, 0.7336,\n",
      "       0.7344, 0.7344, 0.7344, 0.7384, 0.7416, 0.7448, 0.7456, 0.7456,\n",
      "       0.7456, 0.7472, 0.7472, 0.7472, 0.748 , 0.752 , 0.7528, 0.7536,\n",
      "       0.7536, 0.756 , 0.756 , 0.756 , 0.7568, 0.7576, 0.7576, 0.7576,\n",
      "       0.7576, 0.7584, 0.7584, 0.7584, 0.7592, 0.76  , 0.76  , 0.7608,\n",
      "       0.7608, 0.7616, 0.7624, 0.7624, 0.7624, 0.764 , 0.764 , 0.764 ,\n",
      "       0.764 , 0.7648, 0.7648, 0.7664, 0.7664, 0.7672, 0.7696, 0.7704,\n",
      "       0.7704, 0.7712, 0.7728, 0.7736, 0.7736, 0.7744, 0.7744, 0.7744,\n",
      "       0.7752, 0.776 , 0.7768, 0.7768, 0.7768, 0.7768, 0.7768, 0.7776,\n",
      "       0.7784, 0.7784, 0.7792, 0.78  ]), 0.8], [array([0.6408, 0.6464, 0.6576, 0.6768, 0.6904, 0.6952, 0.7   , 0.7008,\n",
      "       0.7024, 0.708 , 0.7104, 0.7104, 0.7128, 0.7136, 0.7152, 0.7184,\n",
      "       0.7184, 0.7216, 0.7224, 0.7256, 0.7264, 0.728 , 0.7288, 0.7296,\n",
      "       0.7328, 0.7328, 0.7328, 0.7328, 0.7344, 0.7368, 0.7368, 0.7368,\n",
      "       0.7376, 0.7424, 0.7432, 0.744 , 0.744 , 0.7448, 0.7448, 0.7448,\n",
      "       0.7464, 0.748 , 0.7496, 0.7496, 0.7528, 0.7552, 0.7552, 0.7568,\n",
      "       0.7568, 0.7568, 0.7576, 0.7608, 0.7616, 0.7616, 0.7616, 0.7616,\n",
      "       0.7632, 0.764 , 0.764 , 0.7656, 0.7672, 0.7672, 0.7672, 0.768 ,\n",
      "       0.7696, 0.7696, 0.7704, 0.7704, 0.772 , 0.772 , 0.772 , 0.7728,\n",
      "       0.7728, 0.7728, 0.7744, 0.7744, 0.7752, 0.7752, 0.7752, 0.776 ,\n",
      "       0.776 , 0.776 , 0.7768, 0.7768, 0.7768, 0.7776, 0.7776, 0.7792,\n",
      "       0.7792, 0.7792, 0.7792, 0.78  , 0.78  , 0.78  , 0.7816, 0.7816,\n",
      "       0.7816, 0.7816, 0.7816, 0.7824]), 0.9]]\n",
      "[array([0.6504, 0.6504, 0.6504, 0.652 , 0.652 , 0.6528, 0.6552, 0.6568,\n",
      "       0.6616, 0.6672, 0.6792, 0.6792, 0.6832, 0.6848, 0.6888, 0.6896,\n",
      "       0.696 , 0.6968, 0.7   , 0.7   , 0.7008, 0.7048, 0.7048, 0.708 ,\n",
      "       0.7104, 0.7112, 0.7112, 0.7128, 0.7128, 0.7144, 0.7176, 0.7176,\n",
      "       0.7192, 0.7192, 0.7232, 0.7264, 0.7272, 0.728 , 0.7288, 0.732 ,\n",
      "       0.732 , 0.7336, 0.7344, 0.7368, 0.7368, 0.7368, 0.7376, 0.7384,\n",
      "       0.7384, 0.74  , 0.7416, 0.7424, 0.7432, 0.7432, 0.7448, 0.7464,\n",
      "       0.7472, 0.7472, 0.748 , 0.7496, 0.7496, 0.7496, 0.7512, 0.756 ,\n",
      "       0.756 , 0.7584, 0.7592, 0.76  , 0.7608, 0.7608, 0.7656, 0.7656,\n",
      "       0.7664, 0.7664, 0.7664, 0.7704, 0.772 , 0.772 , 0.7728, 0.7736,\n",
      "       0.7736, 0.7752, 0.7752, 0.776 , 0.776 , 0.7776, 0.7792, 0.7792,\n",
      "       0.7792, 0.78  , 0.7832, 0.7832, 0.784 , 0.7848, 0.7856, 0.7856,\n",
      "       0.7864, 0.7872, 0.7872, 0.788 ]), 0.1]\n",
      "[array([0.6304, 0.6368, 0.6432, 0.6504, 0.656 , 0.6568, 0.6576, 0.6664,\n",
      "       0.6672, 0.668 , 0.6704, 0.6728, 0.6768, 0.6824, 0.6832, 0.6856,\n",
      "       0.6912, 0.6912, 0.6912, 0.6944, 0.696 , 0.696 , 0.6984, 0.7016,\n",
      "       0.7024, 0.7024, 0.704 , 0.7064, 0.7064, 0.7064, 0.7064, 0.708 ,\n",
      "       0.7104, 0.7112, 0.7112, 0.7128, 0.7152, 0.7152, 0.7152, 0.716 ,\n",
      "       0.7168, 0.7192, 0.7232, 0.724 , 0.7248, 0.7264, 0.7264, 0.7264,\n",
      "       0.7344, 0.7352, 0.736 , 0.7376, 0.7384, 0.7384, 0.74  , 0.74  ,\n",
      "       0.7408, 0.7424, 0.7432, 0.7432, 0.7464, 0.7464, 0.7464, 0.7464,\n",
      "       0.7504, 0.7504, 0.7504, 0.7504, 0.7504, 0.7504, 0.7504, 0.7504,\n",
      "       0.7504, 0.7504, 0.7504, 0.7512, 0.752 , 0.752 , 0.752 , 0.752 ,\n",
      "       0.752 , 0.7528, 0.7528, 0.7536, 0.7536, 0.7536, 0.7536, 0.7536,\n",
      "       0.7536, 0.7536, 0.7544, 0.7544, 0.7544, 0.7544, 0.7544, 0.7552,\n",
      "       0.7568, 0.7568, 0.7576, 0.7576]), 0.2]\n",
      "[array([0.6432, 0.648 , 0.6496, 0.6552, 0.6592, 0.6608, 0.6672, 0.6672,\n",
      "       0.6712, 0.6768, 0.6768, 0.68  , 0.6824, 0.692 , 0.692 , 0.6928,\n",
      "       0.6992, 0.6992, 0.7008, 0.7032, 0.7072, 0.7152, 0.716 , 0.7176,\n",
      "       0.72  , 0.7232, 0.7248, 0.7296, 0.732 , 0.7336, 0.736 , 0.74  ,\n",
      "       0.7408, 0.7432, 0.744 , 0.7448, 0.7448, 0.7472, 0.7496, 0.7496,\n",
      "       0.7496, 0.752 , 0.7536, 0.7552, 0.7552, 0.756 , 0.7608, 0.7624,\n",
      "       0.7624, 0.764 , 0.7648, 0.7664, 0.7688, 0.7696, 0.7704, 0.772 ,\n",
      "       0.7728, 0.7736, 0.7752, 0.7752, 0.7752, 0.7752, 0.7768, 0.7768,\n",
      "       0.7768, 0.7776, 0.7784, 0.7784, 0.7784, 0.7792, 0.7792, 0.7808,\n",
      "       0.7808, 0.7816, 0.7816, 0.784 , 0.784 , 0.7848, 0.7856, 0.7856,\n",
      "       0.7864, 0.7872, 0.788 , 0.7888, 0.7896, 0.792 , 0.792 , 0.7928,\n",
      "       0.7928, 0.7928, 0.7936, 0.7944, 0.7944, 0.7992, 0.8   , 0.8   ,\n",
      "       0.8016, 0.8016, 0.8024, 0.8024]), 0.3]\n",
      "[array([0.6416, 0.6424, 0.644 , 0.6552, 0.6624, 0.6648, 0.672 , 0.6728,\n",
      "       0.6776, 0.6832, 0.6856, 0.696 , 0.7   , 0.7024, 0.7032, 0.704 ,\n",
      "       0.7048, 0.7056, 0.7056, 0.7056, 0.7088, 0.7104, 0.7128, 0.7128,\n",
      "       0.7152, 0.7152, 0.716 , 0.7168, 0.7168, 0.7176, 0.7176, 0.7184,\n",
      "       0.7192, 0.7232, 0.7256, 0.7264, 0.7264, 0.7264, 0.7288, 0.7288,\n",
      "       0.7288, 0.7296, 0.7296, 0.7296, 0.732 , 0.732 , 0.732 , 0.7328,\n",
      "       0.7352, 0.7368, 0.7376, 0.7376, 0.74  , 0.74  , 0.74  , 0.7416,\n",
      "       0.7416, 0.7416, 0.7464, 0.7472, 0.7472, 0.7472, 0.7496, 0.7512,\n",
      "       0.7512, 0.752 , 0.752 , 0.7528, 0.7536, 0.7536, 0.7536, 0.7544,\n",
      "       0.7552, 0.7552, 0.7552, 0.7552, 0.7552, 0.7552, 0.7552, 0.7552,\n",
      "       0.7552, 0.756 , 0.756 , 0.756 , 0.756 , 0.7584, 0.7584, 0.7616,\n",
      "       0.7616, 0.7632, 0.7632, 0.7632, 0.7688, 0.7688, 0.7688, 0.7688,\n",
      "       0.7696, 0.7712, 0.7712, 0.772 ]), 0.4]\n",
      "[array([0.6496, 0.6568, 0.6616, 0.6632, 0.672 , 0.6776, 0.6824, 0.6848,\n",
      "       0.6912, 0.6912, 0.6944, 0.6984, 0.7016, 0.7032, 0.7064, 0.708 ,\n",
      "       0.7096, 0.7112, 0.7136, 0.7184, 0.7216, 0.7216, 0.7264, 0.728 ,\n",
      "       0.7296, 0.732 , 0.7328, 0.7328, 0.7352, 0.7384, 0.7392, 0.7424,\n",
      "       0.7432, 0.744 , 0.7464, 0.7512, 0.752 , 0.7528, 0.7528, 0.7536,\n",
      "       0.7536, 0.7536, 0.7552, 0.7576, 0.7592, 0.76  , 0.7608, 0.7624,\n",
      "       0.7624, 0.7624, 0.7632, 0.764 , 0.7664, 0.7664, 0.7664, 0.7672,\n",
      "       0.768 , 0.7704, 0.7704, 0.7744, 0.7752, 0.776 , 0.7768, 0.7776,\n",
      "       0.7776, 0.7776, 0.7784, 0.7792, 0.7792, 0.7808, 0.7808, 0.7808,\n",
      "       0.7808, 0.7808, 0.7808, 0.7808, 0.7816, 0.7816, 0.7816, 0.7824,\n",
      "       0.7824, 0.7832, 0.784 , 0.7856, 0.7856, 0.7872, 0.788 , 0.7888,\n",
      "       0.7888, 0.7888, 0.792 , 0.792 , 0.7936, 0.7936, 0.7936, 0.7944,\n",
      "       0.7944, 0.7944, 0.7944, 0.7952]), 0.5]\n",
      "[array([0.6256, 0.6336, 0.6456, 0.6576, 0.6624, 0.6664, 0.6712, 0.6816,\n",
      "       0.6824, 0.6832, 0.6856, 0.6872, 0.6888, 0.6904, 0.692 , 0.6944,\n",
      "       0.6968, 0.6984, 0.7   , 0.7024, 0.7032, 0.7048, 0.7072, 0.708 ,\n",
      "       0.7088, 0.7104, 0.7144, 0.7144, 0.7144, 0.7224, 0.7224, 0.7224,\n",
      "       0.7248, 0.7256, 0.7272, 0.7296, 0.7312, 0.7328, 0.7336, 0.7336,\n",
      "       0.7376, 0.7376, 0.7384, 0.74  , 0.7408, 0.7416, 0.7424, 0.7424,\n",
      "       0.7424, 0.7456, 0.7504, 0.7504, 0.752 , 0.7528, 0.7536, 0.7536,\n",
      "       0.756 , 0.756 , 0.7576, 0.7576, 0.7576, 0.7592, 0.7592, 0.76  ,\n",
      "       0.76  , 0.7608, 0.764 , 0.764 , 0.7648, 0.7648, 0.7664, 0.7672,\n",
      "       0.7688, 0.7696, 0.7696, 0.7728, 0.7744, 0.7744, 0.7784, 0.7792,\n",
      "       0.78  , 0.78  , 0.78  , 0.78  , 0.78  , 0.78  , 0.78  , 0.78  ,\n",
      "       0.7808, 0.7816, 0.7816, 0.7816, 0.7824, 0.7832, 0.7832, 0.7832,\n",
      "       0.7832, 0.7848, 0.7848, 0.7856]), 0.6]\n",
      "[array([0.6384, 0.6472, 0.6608, 0.668 , 0.668 , 0.6776, 0.6864, 0.6864,\n",
      "       0.688 , 0.6904, 0.6912, 0.696 , 0.6968, 0.6976, 0.6984, 0.7   ,\n",
      "       0.7032, 0.7064, 0.7112, 0.7128, 0.7168, 0.7192, 0.7216, 0.7248,\n",
      "       0.7264, 0.7264, 0.7312, 0.732 , 0.732 , 0.7328, 0.7328, 0.736 ,\n",
      "       0.7368, 0.7392, 0.7408, 0.7416, 0.7416, 0.7424, 0.7432, 0.7432,\n",
      "       0.7432, 0.7456, 0.7464, 0.7464, 0.7464, 0.7496, 0.752 , 0.7528,\n",
      "       0.7552, 0.7552, 0.7584, 0.76  , 0.76  , 0.7608, 0.7608, 0.7616,\n",
      "       0.7616, 0.764 , 0.764 , 0.764 , 0.7648, 0.7664, 0.7688, 0.7712,\n",
      "       0.7736, 0.7736, 0.7752, 0.7752, 0.7776, 0.7776, 0.7784, 0.7784,\n",
      "       0.7784, 0.7792, 0.7792, 0.7792, 0.7792, 0.7792, 0.78  , 0.78  ,\n",
      "       0.78  , 0.7808, 0.7808, 0.7808, 0.7816, 0.7824, 0.7824, 0.7832,\n",
      "       0.7832, 0.784 , 0.784 , 0.784 , 0.784 , 0.784 , 0.784 , 0.784 ,\n",
      "       0.784 , 0.784 , 0.784 , 0.784 ]), 0.7]\n",
      "[array([0.6328, 0.6416, 0.6544, 0.6656, 0.6752, 0.6784, 0.6808, 0.6816,\n",
      "       0.6832, 0.6848, 0.688 , 0.6888, 0.6912, 0.6928, 0.696 , 0.6984,\n",
      "       0.7   , 0.7024, 0.7032, 0.7048, 0.712 , 0.712 , 0.72  , 0.72  ,\n",
      "       0.72  , 0.724 , 0.7248, 0.7248, 0.7272, 0.7288, 0.7336, 0.7336,\n",
      "       0.7344, 0.7344, 0.7344, 0.7384, 0.7416, 0.7448, 0.7456, 0.7456,\n",
      "       0.7456, 0.7472, 0.7472, 0.7472, 0.748 , 0.752 , 0.7528, 0.7536,\n",
      "       0.7536, 0.756 , 0.756 , 0.756 , 0.7568, 0.7576, 0.7576, 0.7576,\n",
      "       0.7576, 0.7584, 0.7584, 0.7584, 0.7592, 0.76  , 0.76  , 0.7608,\n",
      "       0.7608, 0.7616, 0.7624, 0.7624, 0.7624, 0.764 , 0.764 , 0.764 ,\n",
      "       0.764 , 0.7648, 0.7648, 0.7664, 0.7664, 0.7672, 0.7696, 0.7704,\n",
      "       0.7704, 0.7712, 0.7728, 0.7736, 0.7736, 0.7744, 0.7744, 0.7744,\n",
      "       0.7752, 0.776 , 0.7768, 0.7768, 0.7768, 0.7768, 0.7768, 0.7776,\n",
      "       0.7784, 0.7784, 0.7792, 0.78  ]), 0.8]\n",
      "[array([0.6408, 0.6464, 0.6576, 0.6768, 0.6904, 0.6952, 0.7   , 0.7008,\n",
      "       0.7024, 0.708 , 0.7104, 0.7104, 0.7128, 0.7136, 0.7152, 0.7184,\n",
      "       0.7184, 0.7216, 0.7224, 0.7256, 0.7264, 0.728 , 0.7288, 0.7296,\n",
      "       0.7328, 0.7328, 0.7328, 0.7328, 0.7344, 0.7368, 0.7368, 0.7368,\n",
      "       0.7376, 0.7424, 0.7432, 0.744 , 0.744 , 0.7448, 0.7448, 0.7448,\n",
      "       0.7464, 0.748 , 0.7496, 0.7496, 0.7528, 0.7552, 0.7552, 0.7568,\n",
      "       0.7568, 0.7568, 0.7576, 0.7608, 0.7616, 0.7616, 0.7616, 0.7616,\n",
      "       0.7632, 0.764 , 0.764 , 0.7656, 0.7672, 0.7672, 0.7672, 0.768 ,\n",
      "       0.7696, 0.7696, 0.7704, 0.7704, 0.772 , 0.772 , 0.772 , 0.7728,\n",
      "       0.7728, 0.7728, 0.7744, 0.7744, 0.7752, 0.7752, 0.7752, 0.776 ,\n",
      "       0.776 , 0.776 , 0.7768, 0.7768, 0.7768, 0.7776, 0.7776, 0.7792,\n",
      "       0.7792, 0.7792, 0.7792, 0.78  , 0.78  , 0.78  , 0.7816, 0.7816,\n",
      "       0.7816, 0.7816, 0.7816, 0.7824]), 0.9]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('pickles/ga/n_run_az_ga_100fc_pt_avg.pkl', 'rb') as rf:\n",
    "    co_pt = pickle.load(rf)\n",
    "    print(co_pt[0])\n",
    "    for i in co_pt[0]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([0.6504, 0.6504, 0.6504, 0.652 , 0.652 , 0.6528, 0.6552, 0.6568,\n",
       "         0.6616, 0.6672, 0.6792, 0.6792, 0.6832, 0.6848, 0.6888, 0.6896,\n",
       "         0.696 , 0.6968, 0.7   , 0.7   , 0.7008, 0.7048, 0.7048, 0.708 ,\n",
       "         0.7104, 0.7112, 0.7112, 0.7128, 0.7128, 0.7144, 0.7176, 0.7176,\n",
       "         0.7192, 0.7192, 0.7232, 0.7264, 0.7272, 0.728 , 0.7288, 0.732 ,\n",
       "         0.732 , 0.7336, 0.7344, 0.7368, 0.7368, 0.7368, 0.7376, 0.7384,\n",
       "         0.7384, 0.74  , 0.7416, 0.7424, 0.7432, 0.7432, 0.7448, 0.7464,\n",
       "         0.7472, 0.7472, 0.748 , 0.7496, 0.7496, 0.7496, 0.7512, 0.756 ,\n",
       "         0.756 , 0.7584, 0.7592, 0.76  , 0.7608, 0.7608, 0.7656, 0.7656,\n",
       "         0.7664, 0.7664, 0.7664, 0.7704, 0.772 , 0.772 , 0.7728, 0.7736,\n",
       "         0.7736, 0.7752, 0.7752, 0.776 , 0.776 , 0.7776, 0.7792, 0.7792,\n",
       "         0.7792, 0.78  , 0.7832, 0.7832, 0.784 , 0.7848, 0.7856, 0.7856,\n",
       "         0.7864, 0.7872, 0.7872, 0.788 ]),\n",
       "  0.1],\n",
       " [array([0.6304, 0.6368, 0.6432, 0.6504, 0.656 , 0.6568, 0.6576, 0.6664,\n",
       "         0.6672, 0.668 , 0.6704, 0.6728, 0.6768, 0.6824, 0.6832, 0.6856,\n",
       "         0.6912, 0.6912, 0.6912, 0.6944, 0.696 , 0.696 , 0.6984, 0.7016,\n",
       "         0.7024, 0.7024, 0.704 , 0.7064, 0.7064, 0.7064, 0.7064, 0.708 ,\n",
       "         0.7104, 0.7112, 0.7112, 0.7128, 0.7152, 0.7152, 0.7152, 0.716 ,\n",
       "         0.7168, 0.7192, 0.7232, 0.724 , 0.7248, 0.7264, 0.7264, 0.7264,\n",
       "         0.7344, 0.7352, 0.736 , 0.7376, 0.7384, 0.7384, 0.74  , 0.74  ,\n",
       "         0.7408, 0.7424, 0.7432, 0.7432, 0.7464, 0.7464, 0.7464, 0.7464,\n",
       "         0.7504, 0.7504, 0.7504, 0.7504, 0.7504, 0.7504, 0.7504, 0.7504,\n",
       "         0.7504, 0.7504, 0.7504, 0.7512, 0.752 , 0.752 , 0.752 , 0.752 ,\n",
       "         0.752 , 0.7528, 0.7528, 0.7536, 0.7536, 0.7536, 0.7536, 0.7536,\n",
       "         0.7536, 0.7536, 0.7544, 0.7544, 0.7544, 0.7544, 0.7544, 0.7552,\n",
       "         0.7568, 0.7568, 0.7576, 0.7576]),\n",
       "  0.2],\n",
       " [array([0.6432, 0.648 , 0.6496, 0.6552, 0.6592, 0.6608, 0.6672, 0.6672,\n",
       "         0.6712, 0.6768, 0.6768, 0.68  , 0.6824, 0.692 , 0.692 , 0.6928,\n",
       "         0.6992, 0.6992, 0.7008, 0.7032, 0.7072, 0.7152, 0.716 , 0.7176,\n",
       "         0.72  , 0.7232, 0.7248, 0.7296, 0.732 , 0.7336, 0.736 , 0.74  ,\n",
       "         0.7408, 0.7432, 0.744 , 0.7448, 0.7448, 0.7472, 0.7496, 0.7496,\n",
       "         0.7496, 0.752 , 0.7536, 0.7552, 0.7552, 0.756 , 0.7608, 0.7624,\n",
       "         0.7624, 0.764 , 0.7648, 0.7664, 0.7688, 0.7696, 0.7704, 0.772 ,\n",
       "         0.7728, 0.7736, 0.7752, 0.7752, 0.7752, 0.7752, 0.7768, 0.7768,\n",
       "         0.7768, 0.7776, 0.7784, 0.7784, 0.7784, 0.7792, 0.7792, 0.7808,\n",
       "         0.7808, 0.7816, 0.7816, 0.784 , 0.784 , 0.7848, 0.7856, 0.7856,\n",
       "         0.7864, 0.7872, 0.788 , 0.7888, 0.7896, 0.792 , 0.792 , 0.7928,\n",
       "         0.7928, 0.7928, 0.7936, 0.7944, 0.7944, 0.7992, 0.8   , 0.8   ,\n",
       "         0.8016, 0.8016, 0.8024, 0.8024]),\n",
       "  0.3],\n",
       " [array([0.6416, 0.6424, 0.644 , 0.6552, 0.6624, 0.6648, 0.672 , 0.6728,\n",
       "         0.6776, 0.6832, 0.6856, 0.696 , 0.7   , 0.7024, 0.7032, 0.704 ,\n",
       "         0.7048, 0.7056, 0.7056, 0.7056, 0.7088, 0.7104, 0.7128, 0.7128,\n",
       "         0.7152, 0.7152, 0.716 , 0.7168, 0.7168, 0.7176, 0.7176, 0.7184,\n",
       "         0.7192, 0.7232, 0.7256, 0.7264, 0.7264, 0.7264, 0.7288, 0.7288,\n",
       "         0.7288, 0.7296, 0.7296, 0.7296, 0.732 , 0.732 , 0.732 , 0.7328,\n",
       "         0.7352, 0.7368, 0.7376, 0.7376, 0.74  , 0.74  , 0.74  , 0.7416,\n",
       "         0.7416, 0.7416, 0.7464, 0.7472, 0.7472, 0.7472, 0.7496, 0.7512,\n",
       "         0.7512, 0.752 , 0.752 , 0.7528, 0.7536, 0.7536, 0.7536, 0.7544,\n",
       "         0.7552, 0.7552, 0.7552, 0.7552, 0.7552, 0.7552, 0.7552, 0.7552,\n",
       "         0.7552, 0.756 , 0.756 , 0.756 , 0.756 , 0.7584, 0.7584, 0.7616,\n",
       "         0.7616, 0.7632, 0.7632, 0.7632, 0.7688, 0.7688, 0.7688, 0.7688,\n",
       "         0.7696, 0.7712, 0.7712, 0.772 ]),\n",
       "  0.4],\n",
       " [array([0.6496, 0.6568, 0.6616, 0.6632, 0.672 , 0.6776, 0.6824, 0.6848,\n",
       "         0.6912, 0.6912, 0.6944, 0.6984, 0.7016, 0.7032, 0.7064, 0.708 ,\n",
       "         0.7096, 0.7112, 0.7136, 0.7184, 0.7216, 0.7216, 0.7264, 0.728 ,\n",
       "         0.7296, 0.732 , 0.7328, 0.7328, 0.7352, 0.7384, 0.7392, 0.7424,\n",
       "         0.7432, 0.744 , 0.7464, 0.7512, 0.752 , 0.7528, 0.7528, 0.7536,\n",
       "         0.7536, 0.7536, 0.7552, 0.7576, 0.7592, 0.76  , 0.7608, 0.7624,\n",
       "         0.7624, 0.7624, 0.7632, 0.764 , 0.7664, 0.7664, 0.7664, 0.7672,\n",
       "         0.768 , 0.7704, 0.7704, 0.7744, 0.7752, 0.776 , 0.7768, 0.7776,\n",
       "         0.7776, 0.7776, 0.7784, 0.7792, 0.7792, 0.7808, 0.7808, 0.7808,\n",
       "         0.7808, 0.7808, 0.7808, 0.7808, 0.7816, 0.7816, 0.7816, 0.7824,\n",
       "         0.7824, 0.7832, 0.784 , 0.7856, 0.7856, 0.7872, 0.788 , 0.7888,\n",
       "         0.7888, 0.7888, 0.792 , 0.792 , 0.7936, 0.7936, 0.7936, 0.7944,\n",
       "         0.7944, 0.7944, 0.7944, 0.7952]),\n",
       "  0.5],\n",
       " [array([0.6256, 0.6336, 0.6456, 0.6576, 0.6624, 0.6664, 0.6712, 0.6816,\n",
       "         0.6824, 0.6832, 0.6856, 0.6872, 0.6888, 0.6904, 0.692 , 0.6944,\n",
       "         0.6968, 0.6984, 0.7   , 0.7024, 0.7032, 0.7048, 0.7072, 0.708 ,\n",
       "         0.7088, 0.7104, 0.7144, 0.7144, 0.7144, 0.7224, 0.7224, 0.7224,\n",
       "         0.7248, 0.7256, 0.7272, 0.7296, 0.7312, 0.7328, 0.7336, 0.7336,\n",
       "         0.7376, 0.7376, 0.7384, 0.74  , 0.7408, 0.7416, 0.7424, 0.7424,\n",
       "         0.7424, 0.7456, 0.7504, 0.7504, 0.752 , 0.7528, 0.7536, 0.7536,\n",
       "         0.756 , 0.756 , 0.7576, 0.7576, 0.7576, 0.7592, 0.7592, 0.76  ,\n",
       "         0.76  , 0.7608, 0.764 , 0.764 , 0.7648, 0.7648, 0.7664, 0.7672,\n",
       "         0.7688, 0.7696, 0.7696, 0.7728, 0.7744, 0.7744, 0.7784, 0.7792,\n",
       "         0.78  , 0.78  , 0.78  , 0.78  , 0.78  , 0.78  , 0.78  , 0.78  ,\n",
       "         0.7808, 0.7816, 0.7816, 0.7816, 0.7824, 0.7832, 0.7832, 0.7832,\n",
       "         0.7832, 0.7848, 0.7848, 0.7856]),\n",
       "  0.6],\n",
       " [array([0.6384, 0.6472, 0.6608, 0.668 , 0.668 , 0.6776, 0.6864, 0.6864,\n",
       "         0.688 , 0.6904, 0.6912, 0.696 , 0.6968, 0.6976, 0.6984, 0.7   ,\n",
       "         0.7032, 0.7064, 0.7112, 0.7128, 0.7168, 0.7192, 0.7216, 0.7248,\n",
       "         0.7264, 0.7264, 0.7312, 0.732 , 0.732 , 0.7328, 0.7328, 0.736 ,\n",
       "         0.7368, 0.7392, 0.7408, 0.7416, 0.7416, 0.7424, 0.7432, 0.7432,\n",
       "         0.7432, 0.7456, 0.7464, 0.7464, 0.7464, 0.7496, 0.752 , 0.7528,\n",
       "         0.7552, 0.7552, 0.7584, 0.76  , 0.76  , 0.7608, 0.7608, 0.7616,\n",
       "         0.7616, 0.764 , 0.764 , 0.764 , 0.7648, 0.7664, 0.7688, 0.7712,\n",
       "         0.7736, 0.7736, 0.7752, 0.7752, 0.7776, 0.7776, 0.7784, 0.7784,\n",
       "         0.7784, 0.7792, 0.7792, 0.7792, 0.7792, 0.7792, 0.78  , 0.78  ,\n",
       "         0.78  , 0.7808, 0.7808, 0.7808, 0.7816, 0.7824, 0.7824, 0.7832,\n",
       "         0.7832, 0.784 , 0.784 , 0.784 , 0.784 , 0.784 , 0.784 , 0.784 ,\n",
       "         0.784 , 0.784 , 0.784 , 0.784 ]),\n",
       "  0.7],\n",
       " [array([0.6328, 0.6416, 0.6544, 0.6656, 0.6752, 0.6784, 0.6808, 0.6816,\n",
       "         0.6832, 0.6848, 0.688 , 0.6888, 0.6912, 0.6928, 0.696 , 0.6984,\n",
       "         0.7   , 0.7024, 0.7032, 0.7048, 0.712 , 0.712 , 0.72  , 0.72  ,\n",
       "         0.72  , 0.724 , 0.7248, 0.7248, 0.7272, 0.7288, 0.7336, 0.7336,\n",
       "         0.7344, 0.7344, 0.7344, 0.7384, 0.7416, 0.7448, 0.7456, 0.7456,\n",
       "         0.7456, 0.7472, 0.7472, 0.7472, 0.748 , 0.752 , 0.7528, 0.7536,\n",
       "         0.7536, 0.756 , 0.756 , 0.756 , 0.7568, 0.7576, 0.7576, 0.7576,\n",
       "         0.7576, 0.7584, 0.7584, 0.7584, 0.7592, 0.76  , 0.76  , 0.7608,\n",
       "         0.7608, 0.7616, 0.7624, 0.7624, 0.7624, 0.764 , 0.764 , 0.764 ,\n",
       "         0.764 , 0.7648, 0.7648, 0.7664, 0.7664, 0.7672, 0.7696, 0.7704,\n",
       "         0.7704, 0.7712, 0.7728, 0.7736, 0.7736, 0.7744, 0.7744, 0.7744,\n",
       "         0.7752, 0.776 , 0.7768, 0.7768, 0.7768, 0.7768, 0.7768, 0.7776,\n",
       "         0.7784, 0.7784, 0.7792, 0.78  ]),\n",
       "  0.8],\n",
       " [array([0.6408, 0.6464, 0.6576, 0.6768, 0.6904, 0.6952, 0.7   , 0.7008,\n",
       "         0.7024, 0.708 , 0.7104, 0.7104, 0.7128, 0.7136, 0.7152, 0.7184,\n",
       "         0.7184, 0.7216, 0.7224, 0.7256, 0.7264, 0.728 , 0.7288, 0.7296,\n",
       "         0.7328, 0.7328, 0.7328, 0.7328, 0.7344, 0.7368, 0.7368, 0.7368,\n",
       "         0.7376, 0.7424, 0.7432, 0.744 , 0.744 , 0.7448, 0.7448, 0.7448,\n",
       "         0.7464, 0.748 , 0.7496, 0.7496, 0.7528, 0.7552, 0.7552, 0.7568,\n",
       "         0.7568, 0.7568, 0.7576, 0.7608, 0.7616, 0.7616, 0.7616, 0.7616,\n",
       "         0.7632, 0.764 , 0.764 , 0.7656, 0.7672, 0.7672, 0.7672, 0.768 ,\n",
       "         0.7696, 0.7696, 0.7704, 0.7704, 0.772 , 0.772 , 0.772 , 0.7728,\n",
       "         0.7728, 0.7728, 0.7744, 0.7744, 0.7752, 0.7752, 0.7752, 0.776 ,\n",
       "         0.776 , 0.776 , 0.7768, 0.7768, 0.7768, 0.7776, 0.7776, 0.7792,\n",
       "         0.7792, 0.7792, 0.7792, 0.78  , 0.78  , 0.78  , 0.7816, 0.7816,\n",
       "         0.7816, 0.7816, 0.7816, 0.7824]),\n",
       "  0.9]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_pt[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "720be5bf9d441e2d6c30bd91b067816aa682de3307c54a83a56a5f6c3674f9d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
